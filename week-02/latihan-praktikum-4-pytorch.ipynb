{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3QTImHE1Lbfhqz8e3t1R3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpradiptanugroho2020-ops/221230031-Pengantar-ML/blob/main/week-02/latihan-praktikum-4-pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW2KSbEMqXKU",
        "outputId": "5d5a7261-3e3a-4133-9ecb-742a6943bb16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTorch operations completed\n",
            "\n",
            "1Linear layer output (y = XW + b):\n",
            "tensor([[-7.0234],\n",
            "        [ 3.7311],\n",
            "        [-7.6301],\n",
            "        [10.2620],\n",
            "        [ 0.3299]])\n",
            "After ReLU activation:\n",
            "tensor([[ 0.0000],\n",
            "        [ 3.7311],\n",
            "        [ 0.0000],\n",
            "        [10.2620],\n",
            "        [ 0.3299]])\n",
            "Normalized input (batch norm, first 5 rows):\n",
            "tensor([[ 7.5580e-01,  3.8172e-01,  1.8655e-03,  2.5784e+00, -1.3380e+00,\n",
            "          8.6641e-01,  1.1409e-01, -6.7233e-02,  7.9975e-01, -7.3008e-01],\n",
            "        [-4.9321e-01,  1.0234e+00,  4.8977e-01, -4.9020e-01,  1.0669e+00,\n",
            "         -1.1059e-01, -1.5537e+00, -6.8912e-02, -1.1503e+00, -2.3473e-01],\n",
            "        [ 2.2167e+00,  9.6231e-01,  2.8972e+00, -7.6612e-02, -2.9919e-01,\n",
            "          1.3901e+00,  1.1174e+00,  8.5983e-03,  2.1626e-01,  7.9240e-01],\n",
            "        [-7.6246e-01,  4.5537e-01,  8.7955e-02, -8.6798e-01,  1.5683e+00,\n",
            "         -7.1150e-01, -6.7330e-01, -2.4535e+00, -5.5311e-01,  1.6939e+00],\n",
            "        [-1.7859e+00, -5.7471e-01,  2.1214e-01, -1.0151e+00, -1.6241e+00,\n",
            "         -5.5842e-01,  2.2592e+00,  1.5527e-01, -4.2202e-02,  4.8899e-02]])\n",
            "One-hot encoding result:\n",
            "Labels: [2, 1, 1, 1, 0, 1, 2, 1, 1, 1]\n",
            "tensor([[0., 0., 1.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 1., 0.]])\n",
            "Advanced tensor operations completed successfully\n",
            "Manual matrix multiplication result:\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n",
            "Torch matmul result (for comparison):\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "'''TODO: Implementasi Operasi Dasar Neural Networks'''\n",
        "# Simulasi batch data: 32 samples, 10 features\n",
        "batch_size, n_features = 32, 10\n",
        "X = torch.randn(batch_size, n_features)\n",
        "weights = torch.randn(n_features, 1)\n",
        "bias = torch.randn(1)\n",
        "\n",
        "# ✅ TODO 1: Implementasi linear layer manual: y = XW + b\n",
        "def linear_layer(X, W, b):\n",
        "    return torch.matmul(X, W) + b  # Linear transformation\n",
        "\n",
        "output = linear_layer(X, weights, bias)\n",
        "\n",
        "# ✅ TODO 2: Implementasi ReLU activation function\n",
        "def relu_activation(tensor):\n",
        "    return torch.maximum(tensor, torch.tensor(0.0))  # Element-wise max(0, x)\n",
        "\n",
        "activated = relu_activation(output)\n",
        "\n",
        "# ✅ TODO 3: Batch normalization sederhana\n",
        "def simple_batch_norm(tensor, epsilon=1e-5):\n",
        "    mean = tensor.mean(dim=0, keepdim=True)\n",
        "    std = tensor.std(dim=0, keepdim=True)\n",
        "    normalized = (tensor - mean) / (std + epsilon)\n",
        "    return normalized\n",
        "\n",
        "normalized = simple_batch_norm(X)\n",
        "\n",
        "# ✅ TODO 4: One-hot encoding manual\n",
        "def one_hot_pytorch(labels, num_classes):\n",
        "    one_hot = torch.zeros(labels.size(0), num_classes)\n",
        "    one_hot[torch.arange(labels.size(0)), labels] = 1\n",
        "    return one_hot\n",
        "\n",
        "labels = torch.randint(0, 3, (10,))\n",
        "one_hot = one_hot_pytorch(labels, num_classes=3)\n",
        "\n",
        "# ✅ Assertions\n",
        "assert output.shape == (batch_size, 1), \"Linear output shape incorrect\"\n",
        "assert torch.all(activated >= 0), \"ReLU should be >= 0\"\n",
        "assert normalized.shape == X.shape, \"Batch norm should preserve shape\"\n",
        "assert one_hot.shape == (10, 3), \"One-hot shape incorrect\"\n",
        "\n",
        "### BONUS: ADVANCED TENSOR OPERATIONS ###\n",
        "\n",
        "'''TODO: Matrix Multiplication dari Prinsip Dasar'''\n",
        "def manual_matrix_multiply(A, B):\n",
        "    \"\"\"\n",
        "    Implementasi perkalian matriks manual tanpa torch.matmul\n",
        "    \"\"\"\n",
        "    rows_A, cols_A = A.shape\n",
        "    rows_B, cols_B = B.shape\n",
        "    assert cols_A == rows_B, \"Matrix dimensions incompatible\"\n",
        "\n",
        "    result = torch.zeros(rows_A, cols_B)\n",
        "    for i in range(rows_A):\n",
        "        for j in range(cols_B):\n",
        "            result[i, j] = torch.sum(A[i, :] * B[:, j])\n",
        "    return result\n",
        "\n",
        "# Test dengan matriks kecil\n",
        "A = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "B = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "\n",
        "manual_result = manual_matrix_multiply(A, B)\n",
        "torch_result = torch.matmul(A, B)\n",
        "\n",
        "assert torch.allclose(manual_result, torch_result), \"Manual multiplication incorrect\"\n",
        "\n",
        "\n",
        "print(\"✅ PyTorch operations completed\\n\")\n",
        "\n",
        "print(\"1Linear layer output (y = XW + b):\")\n",
        "print(output[:5])\n",
        "\n",
        "print(\"After ReLU activation:\")\n",
        "print(activated[:5])\n",
        "\n",
        "print(\"Normalized input (batch norm, first 5 rows):\")\n",
        "print(normalized[:5])\n",
        "\n",
        "print(\"One-hot encoding result:\")\n",
        "print(\"Labels:\", labels.tolist())\n",
        "print(one_hot)\n",
        "\n",
        "print(\"Advanced tensor operations completed successfully\")\n",
        "\n",
        "print(\"Manual matrix multiplication result:\")\n",
        "print(manual_result)\n",
        "\n",
        "print(\"Torch matmul result (for comparison):\")\n",
        "print(torch_result)\n"
      ]
    }
  ]
}