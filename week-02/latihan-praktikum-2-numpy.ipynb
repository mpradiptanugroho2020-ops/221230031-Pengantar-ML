{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKfcFc9iMniKZkOFUkpl+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpradiptanugroho2020-ops/221230031-Pengantar-ML/blob/main/week-02/latihan-praktikum-2-numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvsGKERHjLvz",
        "outputId": "266b6752-63f2-4869-afa1-13476a381eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ NumPy operations completed successfully\n",
            "✅ NumPy operations completed successfully\n",
            "Original Data (first 5 samples):\n",
            "[[  9.96714153   3.61735699  11.47688538  20.23029856   2.65846625]\n",
            " [  2.65863043  20.79212816  12.67434729   0.30525614  10.42560044]\n",
            " [  0.36582307   0.34270246   7.41962272 -14.13280245 -12.24917833]\n",
            " [ -0.62287529  -5.1283112    8.14247333  -4.08024076  -9.12303701]\n",
            " [ 19.65648769   2.742237     5.67528205  -9.24748186  -0.44382725]]\n",
            "After Z-score Normalization (first 5 samples):\n",
            "[[ 0.604418   -0.21979528  0.75746006  1.461092   -0.18919425]\n",
            " [-0.21141045  1.53420502  0.87977344 -0.62585547  0.53845484]\n",
            " [-0.46735006 -0.55422449  0.34303561 -2.13809665 -1.58578836]\n",
            " [-0.57771567 -1.1129603   0.41687036 -1.08519209 -1.2929218 ]\n",
            " [ 1.68601234 -0.30916828  0.16486193 -1.62640854 -0.47982667]]\n",
            "After Outlier Handling (first 5 samples):\n",
            "[[ 0.604418   -0.21979528  0.75746006  1.461092   -0.18919425]\n",
            " [-0.21141045  1.53420502  0.87977344 -0.62585547  0.53845484]\n",
            " [-0.46735006 -0.55422449  0.34303561 -2.13809665 -1.58578836]\n",
            " [-0.57771567 -1.1129603   0.41687036 -1.08519209 -1.2929218 ]\n",
            " [ 1.68601234 -0.30916828  0.16486193 -1.62640854 -0.47982667]]\n",
            "One-hot Encoding Result:\n",
            "Labels: [0 1 2 0 1 2 0]\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n",
            "Train-Test Split Result:\n",
            "   X_train shape: (80, 5)\n",
            "   X_test shape : (20, 5)\n",
            "   y_train shape: (80,)\n",
            "   y_test shape : (20,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "'''TODO: Implementasi Preprocessing Pipeline'''\n",
        "# Dataset simulasi: 100 samples, 5 features\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 5) * 10 + 5  # Mean=5, Std=10\n",
        "\n",
        "# ✅ TODO 1: Normalisasi Z-score: (x - mean) / std\n",
        "def z_score_normalization(data):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    std[std == 0] = 1\n",
        "    return (data - mean) / std\n",
        "\n",
        "X_normalized = z_score_normalization(X)\n",
        "\n",
        "# ✅ TODO 2: Handle outliers - replace values beyond 3 std with boundaries\n",
        "def handle_outliers(data, std_threshold=3):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    upper_bound = mean + std_threshold * std\n",
        "    lower_bound = mean - std_threshold * std\n",
        "\n",
        "    data_clipped = np.clip(data, lower_bound, upper_bound)\n",
        "    return data_clipped\n",
        "\n",
        "X_cleaned = handle_outliers(X_normalized)\n",
        "\n",
        "# ✅ TODO 3: One-hot encoding untuk label kategorikal\n",
        "def one_hot_encoding(labels):\n",
        "    n_classes = np.max(labels) + 1\n",
        "    one_hot = np.zeros((labels.size, n_classes))\n",
        "    one_hot[np.arange(labels.size), labels] = 1\n",
        "    return one_hot\n",
        "\n",
        "labels = np.array([0, 1, 2, 0, 1, 2, 0])\n",
        "one_hot_labels = one_hot_encoding(labels)\n",
        "\n",
        "# ✅ TODO 4: Train-test split manual\n",
        "def train_test_split_numpy(X, y, test_size=0.2):\n",
        "    n_samples = X.shape[0]\n",
        "    n_test = int(n_samples * test_size)\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    test_idx = indices[:n_test]\n",
        "    train_idx = indices[n_test:]\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split_numpy(X, np.random.randint(0, 3, 100))\n",
        "\n",
        "# ✅ Check hasil\n",
        "assert X_normalized.shape == X.shape, \"Shape should remain same\"\n",
        "assert np.allclose(X_normalized.mean(), 0, atol=1e-10), \"Mean should be ~0 after z-score\"\n",
        "assert np.allclose(X_normalized.std(), 1, atol=1e-10), \"Std should be ~1 after z-score\"\n",
        "print(\"✅ NumPy operations completed successfully\")\n",
        "import numpy as np\n",
        "\n",
        "'''TODO: Implementasi Preprocessing Pipeline'''\n",
        "# Dataset simulasi: 100 samples, 5 features\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 5) * 10 + 5  # Mean=5, Std=10\n",
        "\n",
        "# ✅ TODO 1: Normalisasi Z-score: (x - mean) / std\n",
        "def z_score_normalization(data):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    std[std == 0] = 1\n",
        "    return (data - mean) / std\n",
        "\n",
        "X_normalized = z_score_normalization(X)\n",
        "\n",
        "# ✅ TODO 2: Handle outliers - replace values beyond 3 std with boundaries\n",
        "def handle_outliers(data, std_threshold=3):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    upper_bound = mean + std_threshold * std\n",
        "    lower_bound = mean - std_threshold * std\n",
        "    data_clipped = np.clip(data, lower_bound, upper_bound)\n",
        "    return data_clipped\n",
        "\n",
        "X_cleaned = handle_outliers(X_normalized)\n",
        "\n",
        "# ✅ TODO 3: One-hot encoding untuk label kategorikal\n",
        "def one_hot_encoding(labels):\n",
        "    n_classes = np.max(labels) + 1\n",
        "    one_hot = np.zeros((labels.size, n_classes))\n",
        "    one_hot[np.arange(labels.size), labels] = 1\n",
        "    return one_hot\n",
        "\n",
        "labels = np.array([0, 1, 2, 0, 1, 2, 0])\n",
        "one_hot_labels = one_hot_encoding(labels)\n",
        "\n",
        "# ✅ TODO 4: Train-test split manual\n",
        "def train_test_split_numpy(X, y, test_size=0.2):\n",
        "    n_samples = X.shape[0]\n",
        "    n_test = int(n_samples * test_size)\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    test_idx = indices[:n_test]\n",
        "    train_idx = indices[n_test:]\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split_numpy(X, np.random.randint(0, 3, 100))\n",
        "\n",
        "# ✅ Check hasil\n",
        "assert X_normalized.shape == X.shape, \"Shape should remain same\"\n",
        "assert np.allclose(X_normalized.mean(), 0, atol=1e-10), \"Mean should be ~0 after z-score\"\n",
        "assert np.allclose(X_normalized.std(), 1, atol=1e-10), \"Std should be ~1 after z-score\"\n",
        "print(\"✅ NumPy operations completed successfully\")\n",
        "\n",
        "print(\"Original Data (first 5 samples):\")\n",
        "print(X[:5])\n",
        "\n",
        "print(\"After Z-score Normalization (first 5 samples):\")\n",
        "print(X_normalized[:5])\n",
        "\n",
        "print(\"After Outlier Handling (first 5 samples):\")\n",
        "print(X_cleaned[:5])\n",
        "\n",
        "print(\"One-hot Encoding Result:\")\n",
        "print(\"Labels:\", labels)\n",
        "print(one_hot_labels)\n",
        "\n",
        "print(\"Train-Test Split Result:\")\n",
        "print(f\"   X_train shape: {X_train.shape}\")\n",
        "print(f\"   X_test shape : {X_test.shape}\")\n",
        "print(f\"   y_train shape: {y_train.shape}\")\n",
        "print(f\"   y_test shape : {y_test.shape}\")\n"
      ]
    }
  ]
}